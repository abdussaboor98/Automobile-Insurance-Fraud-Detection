{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sdv.single_table import TVAESynthesizer\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.sampling import Condition\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, STATUS_FAIL\n",
    "from hyperopt.mongoexp import MongoTrials\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\n",
    "    \"../../data/Angoss Knowledge Seeker - carclaims.txt/carclaims_original.csv\"\n",
    ")\n",
    "# Drop row with missing data\n",
    "df.drop(df[df[\"DayOfWeekClaimed\"] == \"0\"].index, inplace=True)\n",
    "# Drop ID column\n",
    "df.drop(columns=\"PolicyNumber\", inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "carclaims_train, carclaims_test = train_test_split(df, test_size=0.2, random_state=141)\n",
    "\n",
    "# Load SDV metadata\n",
    "metadata = Metadata.load_from_json(filepath=\"carclaims_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: : 51000it [00:10, 4833.36it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset shape Counter({'No': 31597, 'Yes': 31597})\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'synthesizer.241121_085835.pkl'\n",
    "\n",
    "synthesizer = TVAESynthesizer.load(filepath=model_filename)\n",
    "\n",
    "major_cnt = carclaims_train['FraudFound'].value_counts()['No']\n",
    "minor_cnt = carclaims_train['FraudFound'].value_counts()['Yes']\n",
    "balance_cnt = major_cnt - minor_cnt\n",
    "\n",
    "# Conditions for balancing the data\n",
    "fraud_samples = Condition(\n",
    "    num_rows=20_000 + balance_cnt,\n",
    "    column_values={'FraudFound': 'Yes'}\n",
    ")\n",
    "non_fraud_samples = Condition(\n",
    "    num_rows=20_000,\n",
    "    column_values={'FraudFound': 'No'}\n",
    ")\n",
    "\n",
    "# Create balanced synthetic data\n",
    "synthetic_data = synthesizer.sample_from_conditions(\n",
    "    # conditions=[fraud_samples],\n",
    "    conditions=[fraud_samples, non_fraud_samples], # Balance and oversample both classes\n",
    "    batch_size=1_000\n",
    ")\n",
    "\n",
    "balanced_data = pd.concat([carclaims_train, synthetic_data], axis=0).reset_index(drop=True)\n",
    "carclaims_test.reset_index(drop=True)\n",
    "print('Balanced dataset shape %s' % Counter(balanced_data['FraudFound']))\n",
    "\n",
    "# X y split\n",
    "X_train = balanced_data.drop('FraudFound', axis=1)\n",
    "y_train = balanced_data['FraudFound']\n",
    "X_test = carclaims_test.drop('FraudFound', axis=1)\n",
    "y_test = carclaims_test['FraudFound']\n",
    "\n",
    "# Encode target variable\n",
    "y_train = y_train.map({'Yes': 1, 'No': 0})\n",
    "y_test = y_test.map({'Yes': 1, 'No': 0})\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Lebel Encode features\n",
    "column_labels = {\n",
    "    'AgeOfPolicyHolder': ['16 to 17', '18 to 20', '21 to 25', '26 to 30', '31 to 35', '36 to 40', '41 to 50', '51 to 65', 'over 65'],\n",
    "    'NumberOfSuppliments': ['none', '1 to 2', '3 to 5', 'more than 5'],\n",
    "    'AddressChange-Claim': ['no change', 'under 6 months', '1 year', '2 to 3 years', '4 to 8 years'],\n",
    "    'NumberOfCars': ['1 vehicle', '2 vehicles', '3 to 4', '5 to 8', 'more than 8'],\n",
    "    'VehiclePrice': ['less than 20,000', '20,000 to 29,000', '30,000 to 39,000', '40,000 to 59,000', '60,000 to 69,000', 'more than 69,000'],\n",
    "    'Days:Policy-Accident': ['none', '1 to 7', '15 to 30', '8 to 15', 'more than 30'],\n",
    "    'Days:Policy-Claim': ['15 to 30', '8 to 15', 'more than 30'],\n",
    "    'PastNumberOfClaims': ['none', '1', '2 to 4', 'more than 4'],\n",
    "    'AgeOfVehicle': ['new', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', 'more than 7'],\n",
    "    'Deductible': [300, 400, 500, 700]\n",
    "}\n",
    "for column, labels in column_labels.items():\n",
    "    oe = OrdinalEncoder(categories=[labels], handle_unknown='error')\n",
    "    X_train[column] = oe.fit_transform(X_train[[column]])\n",
    "    X_test[column] = oe.transform(X_test[[column]])\n",
    "    \n",
    "# one hot encode\n",
    "columns_one_hot = {\n",
    "    'Make': ['Accura', 'BMW', 'Chevrolet', 'Dodge', 'Ferrari', 'Ford', 'Honda', 'Jaguar', 'Lexus', 'Mazda', 'Mecedes', 'Mercury', 'Nisson', 'Pontiac', 'Porche', 'Saab', 'Saturn', 'Toyota', 'VW'],\n",
    "    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "    'DayOfWeek': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    'DayOfWeekClaimed': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    'MonthClaimed': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "    'AccidentArea': ['Rural', 'Urban'],\n",
    "    'Sex': ['Female', 'Male'],\n",
    "    'MaritalStatus': ['Divorced', 'Married', 'Single', 'Widow'],\n",
    "    'PoliceReportFiled': ['No', 'Yes'],\n",
    "    'WitnessPresent': ['No', 'Yes'],\n",
    "    'AgentType': ['External', 'Internal'],\n",
    "    'BasePolicy': ['All Perils', 'Collision', 'Liability'],\n",
    "    'Fault': ['Policy Holder', 'Third Party'],\n",
    "    'PolicyType': ['Sedan - All Perils', 'Sedan - Collision', 'Sedan - Liability','Sport - All Perils', 'Sport - Collision', 'Sport - Liability', 'Utility - All Perils', 'Utility - Collision', 'Utility - Liability'],\n",
    "    'VehicleCategory': ['Sedan', 'Sport', 'Utility'],\n",
    "    'Year': [1994, 1995, 1996],    \n",
    "}\n",
    "for column, labels in columns_one_hot.items():\n",
    "    ohe = OneHotEncoder(sparse_output=False, categories=[labels], drop='first', handle_unknown='error')\n",
    "    encoded_nominal = ohe.fit_transform(X_train[[column]])\n",
    "    X_train = pd.concat([X_train, pd.DataFrame(encoded_nominal, columns=ohe.get_feature_names_out([column]), index=X_train.index)], axis=1)\n",
    "    encoded_nominal = ohe.transform(X_test[[column]])\n",
    "    X_test = pd.concat([X_test, pd.DataFrame(encoded_nominal, columns=ohe.get_feature_names_out([column]), index=X_test.index)], axis=1)\n",
    "    \n",
    "X_test.drop(columns=columns_one_hot.keys(), axis=1, inplace=True)\n",
    "X_train.drop(columns=columns_one_hot.keys(), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'xgb_n_estimators': hp.quniform('xgb_n_estimators', 50, 300, 1),\n",
    "    'xgb_gamma': hp.uniform('xgb_gamma', 1e-6, 1e+1),\n",
    "    'xgb_max_depth': hp.quniform('xgb_max_depth', 2, 20, 1),\n",
    "    'xgb_subsample': hp.uniform('xgb_subsample', 0.4, 1),\n",
    "    'xgb_reg_lambda': hp.quniform('xgb_reg_lambda', 1, 8, 1),\n",
    "    'xgb_learning_rate': hp.uniform('xgb_learning_rate', 0.001, 1),\n",
    "}\n",
    "\n",
    "def train_and_predict(params):\n",
    "    try:\n",
    "        xgb_n_estimators = int(params['xgb_n_estimators'])\n",
    "        xgb_gamma = params['xgb_gamma']\n",
    "        xgb_max_depth = int(params['xgb_max_depth'])\n",
    "        xgb_subsample = params['xgb_subsample']\n",
    "        xgb_learning_rate = params['xgb_learning_rate']\n",
    "        xgb_reg_lambda = params['xgb_reg_lambda']\n",
    "        \n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=xgb_n_estimators,\n",
    "            gamma=xgb_gamma,\n",
    "            max_depth=xgb_max_depth,\n",
    "            booster='gbtree',\n",
    "            learning_rate=xgb_learning_rate,\n",
    "            subsample=xgb_subsample,\n",
    "            reg_lambda=xgb_reg_lambda,\n",
    "            random_state=42,\n",
    "        )\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = xgb.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1 Score: {f1:.4f}\")\n",
    "\n",
    "        return {\n",
    "            \"loss\": -f1,\n",
    "            \"status\": STATUS_OK,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1-score\": f1,\n",
    "            \"xgb_n_estimators\": xgb_n_estimators,\n",
    "            \"xgb_gamma\": xgb_gamma,\n",
    "            \"xgb_max_depth\": xgb_max_depth,\n",
    "            \"xgb_subsample\": xgb_subsample,\n",
    "            \"xgb_learning_rate\": xgb_learning_rate,\n",
    "            \"xgb_reg_lambda\": xgb_reg_lambda,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception encountered: {e}\")\n",
    "        return {'status': STATUS_FAIL, 'exception': str(e)}\n",
    "\n",
    "trials = MongoTrials('mongo://localhost:1234/hyperopt/jobs', exp_key=f'{model_filename}_xgboost')\n",
    "\n",
    "best = fmin(\n",
    "    fn=train_and_predict,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(20),\n",
    "    show_progressbar=True,\n",
    ")\n",
    "\n",
    "print(f\"Best result: {best}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlr503-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
